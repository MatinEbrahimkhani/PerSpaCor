{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdfe7f88a534f05",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-16T18:31:12.440605882Z",
     "start_time": "2023-12-16T18:31:12.439404799Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import (DataCollatorForTokenClassification,\n",
    "                          BertTokenizer,BertForTokenClassification)\n",
    "from transformers import Trainer,TrainingArguments\n",
    "#######\n",
    "from utils.corpusprocessor import CorpusType\n",
    "from utils.corpusprocessor import CorpusLoader\n",
    "from utils.labeler import Labeler\n",
    "from utils.datasetbuilder import DatasetBuilder\n",
    "# Loading the corpus using the custom CorpusLoader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CorpusLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m corpus \u001B[38;5;241m=\u001B[39m \u001B[43mCorpusLoader\u001B[49m()\n\u001B[1;32m      2\u001B[0m bijan_data \u001B[38;5;241m=\u001B[39m corpus\u001B[38;5;241m.\u001B[39mload_bijan(CorpusType\u001B[38;5;241m.\u001B[39mwhole_raw)\n\u001B[1;32m      3\u001B[0m labeler \u001B[38;5;241m=\u001B[39m Labeler( tags\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m),\n\u001B[1;32m      4\u001B[0m                  regexes\u001B[38;5;241m=\u001B[39m(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[^\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mS\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mn\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mv\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mf]\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mu200c\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[1;32m      5\u001B[0m                  chars\u001B[38;5;241m=\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m‌\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m      6\u001B[0m                  class_count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m      7\u001B[0m                  )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'CorpusLoader' is not defined"
     ]
    }
   ],
   "source": [
    "corpus = CorpusLoader()\n",
    "bijan_data = corpus.load_bijan(CorpusType.whole_raw)\n",
    "labeler = Labeler( tags=(1, 2),\n",
    "                 regexes=(r'[^\\S\\r\\n\\v\\f]', r'\\u200c'),\n",
    "                 chars=(\" \", \"‌\"),\n",
    "                 class_count=2,\n",
    "                 )\n",
    "labeler.set_text(bijan_data, corpus_type=CorpusType.whole_raw)\n",
    "chars, labels = labeler.labeler()\n",
    "model_dir = \"./Model3111/\"\n",
    "\n",
    "# pretrained_model = \"HooshvareLab/bert-base-parsbert-uncased\"\n",
    "pretrained_model = \"bert-base-multilingual-uncased\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
    "dataset_builder= DatasetBuilder(tokenizer)\n",
    "# Initializing a data collator for token classification with the pre-trained tokenizer\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "# chars = chars[:2100]\n",
    "# labels = labels[:2100]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T13:54:58.107317238Z",
     "start_time": "2024-01-06T13:54:56.642267222Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "\n",
    "tokens = tokenizer(chars, padding=\"max_length\", is_split_into_words=True,max_length=512)[\"input_ids\"]\n",
    "# Prepare the labels. Here I'm simply padding the labels list with -100s (the default ignore index in PyTorch)\n",
    "labels = labels + [-100] * (len(tokens) - len(labels))\n",
    "# print(tokens)\n",
    "# print(len(tokens))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T19:07:55.486550209Z",
     "start_time": "2023-12-16T18:57:43.399000477Z"
    }
   },
   "id": "111f0050223d8ac1"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "IDs:\t\t\t (5, 512)\n",
      "Labels:\t\t\t (5, 512)\n",
      "Attention Mask:\t (5, 512)\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_mask, labels = dataset_builder.chunck_tokens(tokens, labels,chunk_size=512,summery=True)\n",
    "dataset = Dataset.from_dict({\"input_ids\": input_ids,\n",
    "                             \"labels\": labels,\n",
    "                             \"attention_mask\":attention_mask})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T18:52:43.508055190Z",
     "start_time": "2023-12-16T18:52:43.497524177Z"
    }
   },
   "id": "ab6a5a2a3baa13d"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9865889\n",
      "9876930\n",
      "9876930\n",
      "464 پ 0\n",
      "454 ش 0\n",
      "474 ت 0\n",
      "451 ك 0\n",
      "461 ا 0\n",
      "461 ر 1\n",
      "479 ر 0\n",
      "462 و 0\n",
      "478 ز 0\n",
      "459 ه 2\n",
      "451 د 0\n",
      "461 ا 0\n",
      "476 ر 1\n",
      "481 م 0\n",
      "454 ي 2\n",
      "479 ت 0\n",
      "451 و 0\n",
      "477 ا 0\n",
      "459 ن 0\n",
      "478 د 1\n",
      "476 ه 0\n",
      "481 م 0\n",
      "464 ي 0\n",
      "478 ش 0\n",
      "451 ه 1\n",
      "479 ا 0\n",
      "461 و 1\n",
      "451 ر 0\n",
      "479 ا 1\n",
      "451 و 0\n",
      "459 ا 0\n",
      "451 د 0\n",
      "461 ا 0\n",
      "474 ر 1\n",
      "477 ك 0\n",
      "459 ن 0\n",
      "474 د 1\n",
      "478 ك 0\n",
      "451 ه 1\n",
      "462 ا 0\n",
      "451 ز 1\n",
      "476 ا 0\n",
      "454 م 0\n",
      "457 ت 0\n",
      "451 ح 0\n",
      "477 ا 0\n",
      "451 ن 0\n",
      "454 ا 0\n",
      "477 ت 1\n",
      "454 ن 0\n",
      "461 ت 0\n",
      "463 ر 0\n",
      "459 س 0\n",
      "479 د 1\n",
      "478 و 1\n",
      "476 ه 0\n",
      "481 م 0\n",
      "464 ي 0\n",
      "478 ش 0\n",
      "459 ه 1\n",
      "461 د 0\n",
      "451 ر 1\n",
      "476 ا 0\n",
      "454 م 0\n",
      "457 ت 0\n",
      "451 ح 0\n",
      "477 ا 0\n",
      "451 ن 0\n",
      "454 ا 0\n",
      "476 ت 1\n",
      "458 م 0\n",
      "454 خ 0\n",
      "475 ت 0\n",
      "472 ل 0\n",
      "463 ف 1\n",
      "461 س 0\n",
      "452 ر 0\n",
      "475 ب 0\n",
      "477 ل 0\n",
      "459 ن 0\n",
      "452 د 1\n",
      "451 ب 0\n",
      "464 ا 0\n",
      "459 ش 0\n",
      "119 د 0\n",
      "479 . 1\n",
      "478 و 1\n",
      "476 ه 0\n",
      "478 م 0\n",
      "451 ه 1\n",
      "481 ا 0\n",
      "477 ي 0\n",
      "478 ن 0\n",
      "451 ه 0\n",
      "474 ا 1\n",
      "478 ك 0\n",
      "507 ه 1\n",
      "472 گ 0\n",
      "454 ف 0\n",
      "481 ت 0\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "print(len(labels))\n",
    "print(len(chars))\n",
    "b = 10000\n",
    "for i in range(100):\n",
    "    print(tokens[b+i],chars[b+i],labels[b+i])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T19:34:28.724910700Z",
     "start_time": "2023-12-16T19:34:28.684240155Z"
    }
   },
   "id": "6f3c02e0d6526f83"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "IDs:\t\t\t (5, 512)\n",
      "Labels:\t\t\t (9876930,)\n",
      "Attention Mask:\t (5, 512)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mask_shape = np.array(attention_mask).shape\n",
    "ids_shape = np.array(input_ids).shape\n",
    "lbl_shape = np.array(labels).shape\n",
    "print(\"Shapes\\nIDs:\\t\\t\\t\", ids_shape)\n",
    "print(\"Labels:\\t\\t\\t\", lbl_shape)\n",
    "print(\"Attention Mask:\\t\", mask_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T19:34:33.268215968Z",
     "start_time": "2023-12-16T19:34:33.261549125Z"
    }
   },
   "id": "15767f82af711543"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-16T18:40:27.321791108Z"
    }
   },
   "id": "baa28b6da06357b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(pretrained_model,num_labels=3)\n",
    "import torch\n",
    "# torch.backends.cuda.chunk_size = 512 * 1024 * 1024*2\n",
    "model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29ec6b39dfc8b93c"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "# Setting up training arguments for the Trainer class\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    num_train_epochs=200,\n",
    "    # max_steps=200,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01,\n",
    "    # warmup_steps=500,2\n",
    "    logging_dir=model_dir+'/logs',\n",
    "    save_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# Initializing a Trainer instance with the model, training arguments, dataset, tokenizer, and data collator\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=None,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T18:23:35.298374599Z",
     "start_time": "2023-12-16T18:23:35.057337525Z"
    }
   },
   "id": "67b2d7a2a4ccee39"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      | 651761 KiB | 651761 KiB | 651761 KiB |      0 B   |\\n|       from large pool | 651264 KiB | 651264 KiB | 651264 KiB |      0 B   |\\n|       from small pool |    497 KiB |    497 KiB |    497 KiB |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Active memory         | 651761 KiB | 651761 KiB | 651761 KiB |      0 B   |\\n|       from large pool | 651264 KiB | 651264 KiB | 651264 KiB |      0 B   |\\n|       from small pool |    497 KiB |    497 KiB |    497 KiB |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Requested memory      | 651446 KiB | 651446 KiB | 651446 KiB |      0 B   |\\n|       from large pool | 650949 KiB | 650949 KiB | 650949 KiB |      0 B   |\\n|       from small pool |    497 KiB |    497 KiB |    497 KiB |      0 B   |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   | 690176 KiB | 690176 KiB | 690176 KiB |      0 B   |\\n|       from large pool | 688128 KiB | 688128 KiB | 688128 KiB |      0 B   |\\n|       from small pool |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  38414 KiB |  50534 KiB | 248117 KiB | 209702 KiB |\\n|       from large pool |  36864 KiB |  48896 KiB | 246075 KiB | 209211 KiB |\\n|       from small pool |   1550 KiB |   2042 KiB |   2042 KiB |    491 KiB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     201    |     201    |     201    |       0    |\\n|       from large pool |      74    |      74    |      74    |       0    |\\n|       from small pool |     127    |     127    |     127    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     201    |     201    |     201    |       0    |\\n|       from large pool |      74    |      74    |      74    |       0    |\\n|       from small pool |     127    |     127    |     127    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      20    |      20    |      20    |       0    |\\n|       from large pool |      19    |      19    |      19    |       0    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      19    |      19    |      20    |       1    |\\n|       from large pool |      18    |      18    |      19    |       1    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T18:23:37.990718451Z",
     "start_time": "2023-12-16T18:23:37.987224331Z"
    }
   },
   "id": "2d2e4b0ab41a827"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "torch.backends.cuda.chunk_size = 512 * 1024 * 1024\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:22:35.941502128Z",
     "start_time": "2023-11-05T18:22:35.938669409Z"
    }
   },
   "id": "55dbdbcb6cbb8d1f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matin/Desktop/Masters/venv/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/600 : < :, Epoch 0.33/200]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Training the model on the dataset\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m trainer\u001B[38;5;241m.\u001B[39msave_model(model_dir \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel/\u001B[39m\u001B[38;5;124m\"\u001B[39m) \n",
      "File \u001B[0;32m~/Desktop/Masters/venv/lib/python3.9/site-packages/transformers/trainer.py:1539\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1534\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_wrapped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\n\u001B[1;32m   1536\u001B[0m inner_training_loop \u001B[38;5;241m=\u001B[39m find_executable_batch_size(\n\u001B[1;32m   1537\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inner_training_loop, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_batch_size, args\u001B[38;5;241m.\u001B[39mauto_find_batch_size\n\u001B[1;32m   1538\u001B[0m )\n\u001B[0;32m-> 1539\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1540\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1541\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1542\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1544\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Masters/venv/lib/python3.9/site-packages/transformers/trainer.py:1916\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   1913\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol\u001B[38;5;241m.\u001B[39mshould_training_stop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1915\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_epoch_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[0;32m-> 1916\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_log_save_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m DebugOption\u001B[38;5;241m.\u001B[39mTPU_METRICS_DEBUG \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdebug:\n\u001B[1;32m   1919\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_torch_tpu_available():\n\u001B[1;32m   1920\u001B[0m         \u001B[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Masters/venv/lib/python3.9/site-packages/transformers/trainer.py:2237\u001B[0m, in \u001B[0;36mTrainer._maybe_log_save_evaluate\u001B[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2234\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mstep(metrics[metric_to_check])\n\u001B[1;32m   2236\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol\u001B[38;5;241m.\u001B[39mshould_save:\n\u001B[0;32m-> 2237\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_save_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetrics\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2238\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_save(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n",
      "File \u001B[0;32m~/Desktop/Masters/venv/lib/python3.9/site-packages/transformers/trainer.py:2294\u001B[0m, in \u001B[0;36mTrainer._save_checkpoint\u001B[0;34m(self, model, trial, metrics)\u001B[0m\n\u001B[1;32m   2292\u001B[0m run_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_output_dir(trial\u001B[38;5;241m=\u001B[39mtrial)\n\u001B[1;32m   2293\u001B[0m output_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(run_dir, checkpoint_folder)\n\u001B[0;32m-> 2294\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_internal_call\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   2295\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_deepspeed_enabled:\n\u001B[1;32m   2296\u001B[0m     \u001B[38;5;66;03m# under zero3 model file itself doesn't get saved since it's bogus! Unless deepspeed\u001B[39;00m\n\u001B[1;32m   2297\u001B[0m     \u001B[38;5;66;03m# config `stage3_gather_16bit_weights_on_model_save` is True\u001B[39;00m\n\u001B[1;32m   2298\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_wrapped\u001B[38;5;241m.\u001B[39msave_checkpoint(output_dir)\n",
      "File \u001B[0;32m~/Desktop/Masters/venv/lib/python3.9/site-packages/transformers/trainer.py:2769\u001B[0m, in \u001B[0;36mTrainer.save_model\u001B[0;34m(self, output_dir, _internal_call)\u001B[0m\n\u001B[1;32m   2766\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_wrapped\u001B[38;5;241m.\u001B[39msave_checkpoint(output_dir)\n\u001B[1;32m   2768\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mshould_save:\n\u001B[0;32m-> 2769\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_save\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2771\u001B[0m \u001B[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001B[39;00m\n\u001B[1;32m   2772\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpush_to_hub \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _internal_call:\n",
      "File \u001B[0;32m~/Desktop/Masters/venv/lib/python3.9/site-packages/transformers/trainer.py:2827\u001B[0m, in \u001B[0;36mTrainer._save\u001B[0;34m(self, output_dir, state_dict)\u001B[0m\n\u001B[1;32m   2825\u001B[0m             torch\u001B[38;5;241m.\u001B[39msave(state_dict, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(output_dir, WEIGHTS_NAME))\n\u001B[1;32m   2826\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2827\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2828\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstate_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msafe_serialization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_safetensors\u001B[49m\n\u001B[1;32m   2829\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2831\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2832\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39msave_pretrained(output_dir)\n",
      "File \u001B[0;32m~/Desktop/Masters/venv/lib/python3.9/site-packages/transformers/modeling_utils.py:1847\u001B[0m, in \u001B[0;36mPreTrainedModel.save_pretrained\u001B[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, **kwargs)\u001B[0m\n\u001B[1;32m   1845\u001B[0m         safe_save_file(shard, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(save_directory, shard_file), metadata\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m})\n\u001B[1;32m   1846\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1847\u001B[0m         \u001B[43msave_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshard\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43msave_directory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshard_file\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1849\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1850\u001B[0m     path_to_weights \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(save_directory, _add_variant(WEIGHTS_NAME, variant))\n",
      "File \u001B[0;32m~/Desktop/Masters/venv/lib/python3.9/site-packages/torch/serialization.py:619\u001B[0m, in \u001B[0;36msave\u001B[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001B[0m\n\u001B[1;32m    617\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _use_new_zipfile_serialization:\n\u001B[1;32m    618\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m _open_zipfile_writer(f) \u001B[38;5;28;01mas\u001B[39;00m opened_zipfile:\n\u001B[0;32m--> 619\u001B[0m         \u001B[43m_save\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopened_zipfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpickle_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpickle_protocol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_disable_byteorder_record\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    620\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    621\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Desktop/Masters/venv/lib/python3.9/site-packages/torch/serialization.py:850\u001B[0m, in \u001B[0;36m_save\u001B[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001B[0m\n\u001B[1;32m    846\u001B[0m \u001B[38;5;66;03m# given that we copy things around anyway, we might use storage.cpu()\u001B[39;00m\n\u001B[1;32m    847\u001B[0m \u001B[38;5;66;03m# this means to that to get tensors serialized, you need to implement\u001B[39;00m\n\u001B[1;32m    848\u001B[0m \u001B[38;5;66;03m# .cpu() on the underlying Storage\u001B[39;00m\n\u001B[1;32m    849\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m storage\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 850\u001B[0m     storage \u001B[38;5;241m=\u001B[39m \u001B[43mstorage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    851\u001B[0m \u001B[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001B[39;00m\n\u001B[1;32m    852\u001B[0m num_bytes \u001B[38;5;241m=\u001B[39m storage\u001B[38;5;241m.\u001B[39mnbytes()\n",
      "File \u001B[0;32m~/Desktop/Masters/venv/lib/python3.9/site-packages/torch/storage.py:134\u001B[0m, in \u001B[0;36m_StorageBase.cpu\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Returns a CPU copy of this storage if it's not already on the CPU\"\"\"\u001B[39;00m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 134\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mUntypedStorage\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Training the model on the dataset\n",
    "trainer.train()\n",
    "trainer.save_model(model_dir + \"model/\") "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T18:24:15.174966077Z",
     "start_time": "2023-12-16T18:23:41.200219563Z"
    }
   },
   "id": "6bc32812429e24f4"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.0+cu121\n",
      "Is CUDA supported by this system?\tTrue\n",
      "CUDA version: 12.1\n",
      "ID of current CUDA device:\t0\n",
      "Name of current CUDA device:NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:\",torch.__version__)\n",
    "print(f\"Is CUDA supported by this system?\t{torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device:\t{torch.cuda.current_device()}\")\n",
    "print(f\"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}\")\n",
    "import os\n",
    "print(os.environ.get(\"PYTORCH_CUDA_ALLOC_CONF\"))\n",
    "torch.backends.cuda.chunk_size = 512 * 1024 * 1024"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T18:24:32.957155163Z",
     "start_time": "2023-12-16T18:24:31.011716710Z"
    }
   },
   "id": "f1b83f2b2329a41e"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(0)\n",
    "\n",
    "print(torch.cuda.memory_allocated())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T18:23:22.106033401Z",
     "start_time": "2023-12-16T18:23:22.100620366Z"
    }
   },
   "id": "96e55e060653527d"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T18:23:18.908555495Z",
     "start_time": "2023-12-16T18:23:18.867785094Z"
    }
   },
   "id": "88925086b021c441"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T18:23:13.975022694Z"
    }
   },
   "id": "15c7d3d3892de801"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
